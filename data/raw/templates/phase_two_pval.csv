journal,esi_field,p_value,significance,recommended_required,p_use,p_reporting,stat_sig_use,stat_sig_alpha
JOURNAL OF MANAGEMENT,ECONOMICS & BUSINESS,"Authors will need to confirm when submitting their manuscript to the Journal of Managementthat it meets the following requirements,or the authorship team must provide an explanation for why these conditions cannot be met:

All reported statistical estimates (e.g., regression weights, mean differences) must have corresponding standard errors, andinferential statistics (t, z, or F, depending on which is most pertinent)withprecise pvalues reported (e.g., p=.072, rounded to the third decimal place)rather than in star notation (*) or statistical significant cutoff bands (e.g., p< .05);","Authors will need to confirm when submitting their manuscript to the Journal of Managementthat it meets the following requirements,or the authorship team must provide an explanation for why these conditions cannot be met:

All reported statistical estimates (e.g., regression weights, mean differences) must have corresponding standard errors, andinferential statistics (t, z, or F, depending on which is most pertinent)withprecise pvalues reported (e.g., p=.072, rounded to the third decimal place)rather than in star notation (*) or statistical significant cutoff bands (e.g., p< .05);",NA,NA,NA,NA,NA
JOURNAL OF EXPERIMENTAL MEDICINE,IMMUNOLOGY,"Authors should provide clear, detailed descriptions of their statistical analysis in the Materials and methods section and/or figure legends, including but not limited to the statistical test used, actual p-values, number of biological and technical replicates, measure of center, and measure of variability.",NA,NA,NA,NA,NA,NA
WILDLIFE MONOGRAPHS,PLANT & ANIMAL SCIENCE,"Where possible, report exact probabilities (P = 0.057, not P > 0.05). 

Include in the methods your specific model selection criteria (e.g., ΔAIC < 2, wi> 0.9) or significance threshold (α value).

Include thresholds for significance (e.g., α= 0.05) or specific model selection criteria (e.g., ΔAIC < 2, ∑wi> 0.9) if applicable.

Always try to describe the value and magnitude of the biological effect rather than focusing on the results of statistical analyses.That is, terms such as “fewer” or “smaller” tell us little, and stating that something was “statistically different (P< 0.01)” without providing the actual difference conveys little meaning to the reader.For example, stating, “A (= 43 ± 3 ha) was 25% larger than B (P< 0.001)” conveys more information than simply stating, “A was significantly larger than B.”

Avoid redundant use of the word “significantly” (e.g., write “the means differed [P= 0.016]” instead of “the means differed significantly [P= 0.016]”). Report results of statistical tests or central tendency as in the following examples:(t1 = 2.47, P = 0.013), (F3,12 = 33.10, P = 0.01), (= 22.1, P = 0.029), or (= 7.8, SE = 3.21, n= 46). Present P-values <0.001 as P ≤ 0.001.","Include in the methods your specific model selection criteria (e.g., ΔAIC < 2, wi> 0.9) or significance threshold (α value).

Include thresholds for significance (e.g., α= 0.05) or specific model selection criteria (e.g., ΔAIC < 2, ∑wi> 0.9) if applicable.

Always try to describe the value and magnitude of the biological effect rather than focusing on the results of statistical analyses.That is, terms such as “fewer” or “smaller” tell us little, and stating that something was “statistically different (P< 0.01)” without providing the actual difference conveys little meaning to the reader.For example, stating, “A (= 43 ± 3 ha) was 25% larger than B (P< 0.001)” conveys more information than simply stating, “A was significantly larger than B.”

Avoid redundant use of the word “significantly” (e.g., write “the means differed [P= 0.016]” instead of “the means differed significantly [P= 0.016]”). Report results of statistical tests or central tendency as in the following examples:(t1 = 2.47, P = 0.013), (F3,12 = 33.10, P = 0.01), (= 22.1, P = 0.029), or (= 7.8, SE = 3.21, n= 46). Present P-values <0.001 as P ≤ 0.001.",NA,NA,NA,NA,NA
INTERNATIONAL JOURNAL OF EPIDEMIOLOGY,"SOCIAL SCIENCES, GENERAL","In the IJE we actively discourage the use of the term ""statistically significant"" or just ""significant"" and such statements in method sections as ""findings at p<0.05 were considered significant"". Where used, we ask authors to provide effect estimates with confidence intervals and exact P values, and to refrain from the use of the term ""significant"" in either the results or discussion section of their papers. Our justification of this position is given in the Sterne J, Davey-Smith G. ""Sifting the evidence - What's wrong with significance tests?"" BMJ 2001: 322:226-231. See also Wasserstein RL, Lazar NA. The ASA's statement on p-values: context, process, and purpose. The American Statistician 2016: DOI:10.1080/00031305.2016.1154108","In the IJE we actively discourage the use of the term ""statistically significant"" or just ""significant"" and such statements in method sections as ""findings at p<0.05 were considered significant"". Where used, we ask authors to provide effect estimates with confidence intervals and exact P values, and to refrain from the use of the term ""significant"" in either the results or discussion section of their papers. Our justification of this position is given in the Sterne J, Davey-Smith G. ""Sifting the evidence - What's wrong with significance tests?"" BMJ 2001: 322:226-231. See also Wasserstein RL, Lazar NA. The ASA's statement on p-values: context, process, and purpose. The American Statistician 2016: DOI:10.1080/00031305.2016.1154108",NA,NA,NA,NA,NA
PSYCHOTHERAPY AND PSYCHOSOMATICS,PSYCHIATRY_PSYCHOLOGY,"All significant results must include the test value, degree(s) of freedom, and probability level.","All significant results must include the test value, degree(s) of freedom, and probability level.",NA,NA,NA,NA,NA
AMERICAN JOURNAL OF PSYCHIATRY,PSYCHIATRY_PSYCHOLOGY,"All significant and important nonsignificant results must include the test value, degree(s) of freedom, and probability","All significant and important nonsignificant results must include the test value, degree(s) of freedom, and probability",NA,NA,NA,NA,NA
JOURNAL OF THE AMERICAN ACADEMY OF CHILD AND ADOLESCENT PSYCHIATRY,PSYCHIATRY_PSYCHOLOGY,"Summarize statistics, and when reporting significant results, include the statistical test used, the value of the test statistic, degrees of freedom, and p values.","Summarize statistics, and when reporting significant results, include the statistical test used, the value of the test statistic, degrees of freedom, and p values.

Abstracts should provide ...main findings (giving specific effect sizes, numerical differences, and their statistical significance, if possible)",NA,NA,NA,NA,NA
Expert Opinion on Drug Delivery,PHARMACOLOGY & TOXICOLOGY,"The sample size of each data point should be shown, with p-values and confidence intervals quoted for significant findings.",NA,NA,NA,NA,NA,NA
NEUROLOGY,NEUROSCIENCE & BEHAVIOR,"Due to the growing concerns on the overuse and misinterpretation of P values, replace P values with estimates of effects or association and corresponding 95% confidence intervals unless the protocol or the statistical analysis plan has specified methods to adjust for multiplicity of testing.  Hence, a well-designed randomized or observational study will have a primary hypothesis for which a P value < 0.05 can be applied after adjustment for testing multiple endpoints associated with that primary hypothesis.","The Journals follow the guidelines outlined by authorities in the genetics research field (Neurology 2001 57:1153-1154 and Nature Genetics 2005:1217-1223). Calculations of statistical significance must make appropriate corrections for multiple testing. After such correction, the (experiment-wise) significance level must not exceed 0.01 and should preferably be smaller than that limit.",NA,NA,NA,NA,NA
BRAIN,NEUROSCIENCE & BEHAVIOR,"For results of statistical tests, authors should report the statistical test that was applied (e.g. two-sample t-test, analysis of covariance), the test statistic (e.g. t, U, F, r), degrees of freedom as subscripts to the test statistic (Lazic, 2010), and the exact probability value (P). Please indicate whether statistical tests were one- or two-tailed, and the alpha-level that was used to determine significance (e.g. P < 0.05).","Please indicate whether statistical tests were one- or two-tailed, and the alpha-level that was used to determine significance (e.g. P < 0.05).",NA,NA,NA,NA,NA
Lancet Respiratory Medicine,CLINICAL MEDICINE,"p values should be given to two significant figures, unless p<0·0001",NA,NA,NA,NA,NA,NA
SCIENCE,Multidisciplinary,"Results of each statistical test should be reported in full with the value of the test statistic and p-value, and not simply reported as significant or non-significant; more than two significant digits on p-values are usually not needed except in situations of extreme multiple testing such as in genetic association studies where stringent corrections for multiple testing might be used.","
The testing level (alpha) and whether one-sided or two-sided testing was used should be reported for each statistical test; typically two-sided testing is appropriate, but if one-sided testing is used its use should be justified...Results of each statistical test should be reported in full with the value of the test statistic and p-value, and not simply reported as significant or non-significant",NA,NA,NA,NA,NA
JOURNAL OF ALLERGY AND CLINICAL IMMUNOLOGY,IMMUNOLOGY,"Every P value should be reported using two digits after the decimal point. If each of the first two digits after the decimal point is zero, then a third digit can be used. If each of the first three digits after the decimal point is zero, then simply report P < .001...If the P value is close to the level to be used for claiming a statistical significance or if each of the first two digits after the decimal point is zero, then a third digit can be used. For example, if the significance level is 0.05, then P = .046 or P = .054 can be reported. Nonsignificant results (e.g., where the P value is >0.05) should be accompanied by P values; it should not simply be stated that they are nonsignificant (NS)...P values alone are not sufficient to report the results of statistical tests.","If the P value is close to the level to be used for claiming a statistical significance or if each of the first two digits after the decimal point is zero, then a third digit can be used. For example, if the significance level is 0.05, then P = .046 or P = .054 can be reported. Nonsignificant results (e.g., where the P value is >0.05) should be accompanied by P values; it should not simply be stated that they are nonsignificant (NS).",NA,NA,NA,NA,NA
CIRCULATION,CLINICAL MEDICINE,Report Hardy-Weinberg statistics or p-values and method of calculating same.,NA,NA,NA,NA,NA,NA
PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,Multidisciplinary,"In statistics section, no explicit mention of p-values but ""measures of evidence strength"": ""full information on the statistical methods and measures used for each table and figure, such as a statistical test, estimates of parameters, exact sample sizes, and measures of evidence strength (frequentist or Bayesian)""

In figure legends section: ""The P value, magnification, or scale bar information should be provided when applicable""",NA,NA,NA,NA,NA,NA
ENVIRONMENTAL HEALTH PERSPECTIVES,ENVIRONMENT_ECOLOGY,"If p-values are used to interpret findings, report actual p-values for all results rather than indicating ranges of p-values or statistical significance only.","If p-values are used to interpret findings, report actual p-values for all results rather than indicating ranges of p-values or statistical significance only...Do not limit results to statistically significant results or selected findings that support the study hypothesis.",NA,NA,NA,NA,NA
LANCET,CLINICAL MEDICINE,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
Lancet Diabetes & Endocrinology,CLINICAL MEDICINE,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
NEW ENGLAND JOURNAL OF MEDICINE,CLINICAL MEDICINE,"Unless one-sided tests are required by study design, such as in noninferiority clinical trials, all reported P values should be two-sided. In general, P values larger than 0.01 should be reported to two decimal places, and those between 0.01 and 0.001 to three decimal places; P values smaller than 0.001 should be reported as P<0.001. Notable exceptions to this policy include P values arising from tests associated with stopping rules in clinical trials or from genome-wide association studies.","Significance tests should be accompanied by confidence intervals for estimated effect sizes, measures of association, or other parameters of interest. The confidence intervals should be adjusted to match any adjustment made to significance levels in the corresponding test.",NA,NA,NA,NA,NA
JOURNAL OF CLINICAL ONCOLOGY,CLINICAL MEDICINE,"For randomized clinical trials, report two-sided P values...If the trial design was Bayesian, used one-sided P values, or was not based on a standard two-sided test, the primary result and conclusion may be described in terms of the original design. However, also include the two-sided P value of a standard test...Report actual P values, not, for example, P >.05. Two digits are sufficient for P > .01.",NA,NA,NA,NA,NA,NA
ANNALS OF INTERNAL MEDICINE,CLINICAL MEDICINE,"9. Statistical Significance and P Values

Avoid interpreting results based upon statistical significance alone, and follow the principles of proper use and interpretation of the p-value from the American Statistical Association. (ASA's Statement on Statistical Significance and P-values) Consider the clinical importance of observed differences and the width of 95% confidence intervals when interpreting results. In situations where results are consistent with 'no difference' be sure to differentiate results that are indeterminate (consistent with clinically meaningful benefits) from those that are negative (rule-out clinically meaningful benefits).

Useful resources:

Greenland S, Senn SJ, Rothman KJ, et al. Statistical tests, P values, confidence intervals and power: a guide to misinterpretations. Eur J Epidemiol. 2016;31:337-350.

Goodman SN, Berlin JA. The use of predicted confidence intervals when planning experiments and the misuse of power when interpreting results. Ann Intern Med. 1994;121:200-206.

Goodman SN. A dirty dozen: twelve p-value misconceptions. Semin Hematol. 2008;45:135-140.

Wasserstein RL, Lazar NA. The ASA's statement on p-values: context, process, and purpose. The American Statistician. 2016;70:129-133. doi:10.1080/00031305.2016.1154108

...

For P values between 0.001 and 0.20, please report the value to the nearest thousandth. For P values greater than 0.20, please report the value to the nearest hundredth. For P values less than 0.001, report as “P<0.001.” ... Only use the word trend when describing a test for trend or dose-response. Avoid the term trend when referring to P values near but not below 0.05. In such instances, simply report a difference and the confidence interval of the difference (if appropriate) with or without the P value...In tables that simply describe the characteristics of 2 or more groups (e.g., Table 1 of a clinical trial): ...Avoid reporting P values as there can be imbalance when P values are not significant (because of small sample size) and balance when P values are significant (because of large sample size).","9. Statistical Significance and P Values

Avoid interpreting results based upon statistical significance alone, and follow the principles of proper use and interpretation of the p-value from the American Statistical Association. (ASA's Statement on Statistical Significance and P-values) Consider the clinical importance of observed differences and the width of 95% confidence intervals when interpreting results. In situations where results are consistent with 'no difference' be sure to differentiate results that are indeterminate (consistent with clinically meaningful benefits) from those that are negative (rule-out clinically meaningful benefits).

Useful resources:

Greenland S, Senn SJ, Rothman KJ, et al. Statistical tests, P values, confidence intervals and power: a guide to misinterpretations. Eur J Epidemiol. 2016;31:337-350.

Goodman SN, Berlin JA. The use of predicted confidence intervals when planning experiments and the misuse of power when interpreting results. Ann Intern Med. 1994;121:200-206.

Goodman SN. A dirty dozen: twelve p-value misconceptions. Semin Hematol. 2008;45:135-140.

Wasserstein RL, Lazar NA. The ASA's statement on p-values: context, process, and purpose. The American Statistician. 2016;70:129-133. doi:10.1080/00031305.2016.1154108


...


Screening covariates

Approaches that select factors for inclusion in a multivariable model only if the factors are “statistically significant” in “bivariate screening” are not optimal. A factor can be a confounder even if it is not statistically significant by itself because it changes the effect of the exposure of interest when it is included in the model, or because it is a confounder only when included with other covariates.

Useful resource:

Sun GW, Shook TL, Kay GL. Inappropriate use of bivariable analysis to screen risk factors for use in multivariable analysis. J Clin Epidemiol. 1996;49:907-16. PMID: 8699212",NA,NA,NA,NA,NA
Science Translational Medicine,BIOLOGY & BIOCHEMISTRY,"The testing level (alpha) and whether one-sided or two-sided testing was used should be reported for each statistical test; typically two-sided testing is appropriate, but if one-sided testing is used its use should be justified.
Adjustments made to alpha levels (e.g., Bonferroni correction) or other procedure used to account for multiple testing (e.g., false discovery rate control) should be reported...Results of each statistical test should be reported in full with the value of the test statistic and p-value, and not simply reported as significant or non-significant; more than two significant digits on p-values are usually not needed except in situations of extreme multiple testing such as in genetic association studies where stringent corrections for multiple testing might be used.","The testing level (alpha) and whether one-sided or two-sided testing was used should be reported for each statistical test; typically two-sided testing is appropriate, but if one-sided testing is used its use should be justified.
...
Results of each statistical test should be reported in full with the value of the test statistic and p-value, and not simply reported as significant or non-significant; more than two significant digits on p-values are usually not needed except in situations of extreme multiple testing such as in genetic association studies where stringent corrections for multiple testing might be used.",NA,NA,NA,NA,NA
STRATEGIC MANAGEMENT JOURNAL,ECONOMICS & BUSINESS,"SMJ no longer accepts papers for publication that report or refer to cutoff levels of statistical significance (p-values). In statistical studies, authors should report either standard errors or exact p-values (without asterisks) or both, and should interpret these values appropriately in the text. Rather than referring to specific cutoff points, the discussion could report confidence intervals, explain the standard errors and/or the probability of observing the results in the particular sample, and assess the implications for the research questions or hypotheses tested.
...
The SMJ editorial on “Creating Repeatable Cumulative Knowledge in Strategic Management” (2016, vol. 37: 257-261) provides more detailed explanation of these policies.","SMJ no longer accepts papers for publication that report or refer to cutoff levels of statistical significance (p-values). In statistical studies, authors should report either standard errors or exact p-values (without asterisks) or both, and should interpret these values appropriately in the text. Rather than referring to specific cutoff points, the discussion could report confidence intervals, explain the standard errors and/or the probability of observing the results in the particular sample, and assess the implications for the research questions or hypotheses tested.
...
Data Snooping and P-hacking
SMJ strongly disapproves of data snooping and p-hacking practices in empirical research. Authors of submitted papers should not search databases for statistically significant coefficients with the intention of subsequently formulating hypotheses that fit the significant coefficients. Authors also should not adapt experimental designs with the primary intention of producing statistically significant results. In addition, authors of submitted papers should address the material significance (magnitude) of the results, in addition to statistical significance.",NA,NA,NA,NA,NA
ECOLOGICAL MONOGRAPHS,ENVIRONMENT_ECOLOGY,"When reporting results, actual P values are preferred. To denote levels of significance, actual P values are generally more informative than symbols such as * and **.","To denote levels of significance, actual P values are generally more informative than symbols such as * and **.
Effect size and biological importance must not be confused with statistical significance.",NA,NA,NA,NA,NA
JOURNAL OF NUTRITION,AGRICULTURAL SCIENCES,"Describe all statistical tests utilized and indicate the probability level (P) at which differences were considered significant. If non-significant P values are reported, use only 2 digits past the decimal (e.g., P=0.15). Present significant P values to a maximum of 4 decimal places (e.g., P<0.0001); using fewer is acceptable.","Describe all statistical tests utilized and indicate the probability level (P) at which differences were considered significant. Use letters or symbols to indicate significant differences. Show statistics of variability (e.g., SD, pooled SEM) and the significance of differences among the data.",NA,NA,NA,NA,NA
LANCET NEUROLOGY,NEUROSCIENCE & BEHAVIOR,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
JAMA Internal Medicine,CLINICAL MEDICINE,"Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). If P values are reported, follow standard conventions for decimal places: for P values less than .001, report as ""P<.001""; for P values between .001 and .01, report the value to the nearest thousandth; for P values greater than or equal to .01, report the value to the nearest hundredth; and for P values greater than .99, report as ""P>.99."" For studies with exponentially small P values (eg, genetic association studies), P values may be reported with exponents (eg, P = 1×10−5).","Report basic numbers only but state if results are statistically significant or not significant;

Do not use inappropriate hedge terms such as marginal significance or trend toward significance for results that are not statistically significant.

State any a priori levels of significance and whether hypothesis tests were 1- or 2-sided.",NA,NA,NA,NA,NA
BRITISH JOURNAL OF PSYCHIATRY,PSYCHIATRY_PSYCHOLOGY,Quantitative studies: abstracts should provide effect sizes with confidence intervals (not P-values alone).,"To report a difference as being statistically significant is generally insufficient, and comment should be made about the magnitude and direction of change. 

The value of test statistics used (e.g. t, F-ratio) should be given as well as their significance levels so that their derivation can be understood
",NA,NA,NA,NA,NA
PLANT JOURNAL,PLANT & ANIMAL SCIENCE,"*, **, *** should be reserved for P-values",NA,NA,NA,NA,NA,NA
JAMA Oncology,CLINICAL MEDICINE,"Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). If P values are reported, follow standard conventions for decimal places: for P values less than .001, report as ""P<.001""; for P values between .001 and .01, report the value to the nearest thousandth; for P values greater than or equal to .01, report the value to the nearest hundredth; and for P values greater than .99, report as ""P>.99."" For studies with exponentially small P values (eg, genetic association studies), P values may be reported with exponents (eg, P = 1×10−5).","Report basic numbers only but state if results are statistically significant or not significant;

Do not use inappropriate hedge terms such as marginal significance or trend toward significance for results that are not statistically significant.

State any a priori levels of significance and whether hypothesis tests were 1- or 2-sided.",NA,NA,NA,NA,NA
NEW PHYTOLOGIST,PLANT & ANIMAL SCIENCE,NA,"If necessary, present results of tests of significance, such as analysis of variance, in addition to tests of variability.",NA,NA,NA,NA,NA
eLife,BIOLOGY & BIOCHEMISTRY,"Report exact p-values wherever possible alongside the summary statistics and 95%
confidence intervals. These should be reported for all key questions and not only
when the p-value is less than 0.05.",NA,NA,NA,NA,NA,NA
EUROPEAN HEART JOURNAL,CLINICAL MEDICINE,"Presentation of p-values: always give numeric value not just ns (p=0.14 and not ns for example). Give one leading digit for the p-values and in the case of very small p-values give p<0.0001.

Comparison of p-values: refrain from comparing the size of p-values when, for example, assessing differences for various groups. This needs some extra-testing.","Please specify the program used, the significance level, and that it is two-sided (which is the rule).

Proving significance of an association – even in a quite complicated model – does not imply causality of the relationship.

Statistical tests offer a rational decision in case of uncertainty. This probabilistic statement is possible only at the price of formality. If your descriptive analysis is in favour of your hypothesis, but the p-value is not significant, you could not prove your case and you should concede this. Even with a p-value 0.05

There are several points to consider:...

p-value is not significant: if the p-value does not reach significance, this is not proof that the scientific hypothesis is not correct. Other factors such as sample size, frequency of the given event or the relative effect size may explain the lack of statistical significance. Whenever a power calculation has been done, a probabilistic statement about the lack of effect can be made.

Significance vs. relevance: a statistically significant result does not imply clinical or scientific relevance even if the p-value is very low. This relevance is a subject-matter decision. In addition to significant p-values it is advisable to give a measure of effect size, in particular for large studies, where effects with little relevance may become statistically significant. The boundaries of a confidence interval may also be useful to assess relevance of potential effects.",NA,NA,NA,NA,NA
Journal of Clinical Microbiology,MICROBIOLOGY,"For all appropriate multigroup comparisons, two P values must be generated and provided in the manuscript. The main P value applies to the overall data set and indicates that within that data set at least two groups differ from each other. The overall P value does not indicate which two groups are different. The main P value and the overall P value should be computed by using a post hoc test.

Statistical significance and biological significance are notthe same. There is nothing magical about a P value of 0.05. When results from large sample sizes are compared, a P value of < 0.05 will often be obtained, as P value is a function of both sample sizeand effect size. If sample sizes are large, then more-rigorous (i.e., smaller) P values may be desirable. If sample sizes are small, Pvalues of > 0.05  may  still  be  important.","Statistical significance and biological significance are notthe same. There is nothing magical about a P value of 0.05. When results from large sample sizes are compared, a P value of < 0.05 will often be obtained, as P value is a function of both sample sizeand effect size. If sample sizes are large, then more-rigorous (i.e., smaller) P values may be desirable. If sample sizes are small, Pvalues of > 0.05  may  still  be  important.  There  should  be  bothstatistical and biological significance to the results and conclusions in the manuscript.

Data presented as endpoints (i.e., LD50and ID50, etc.) contain  both  the  calculated  value  and  a  confidence  interval with a statistical significance associated with it (95%, 99%, orsimilar confidence interval), calculated by logit or probit analysis.",NA,NA,NA,NA,NA
Journal of Allergy and Clinical Immunology-In Practice,IMMUNOLOGY,"• Every P value should be reported using two digits after the decimal point. If each of the first two digits after the decimal point is zero, then a third digit can be used. If each of the first three digits after the decimal point is zero, then simply report P < .001.
• If the P value is close to the level to be used for claiming a statistical significance or if each of the first two digits after the decimal point is zero, then a third digit can be used. For example, if the significance level is 0.05, then P = .046 or P = .054 can be reported. Nonsignificant results (e.g., where the P value is > 0.05) should be accompanied by P values; it should not simply be stated that they are nonsignificant (NS).
• P values alone are not sufficient to report the results of statistical tests. JACI: In Practice’s readers need to see the magnitude of the effects via point estimates and 95% confidence intervals for the group comparisons.","• If the P value is close to the level to be used for claiming a statistical significance or if each of the first two digits after the decimal point is zero, then a third digit can be used. For example, if the significance level is 0.05, then P = .046 or P = .054 can be reported. Nonsignificant results (e.g., where the P value is > 0.05) should be accompanied by P values; it should not simply be stated that they are nonsignificant (NS).",NA,NA,NA,NA,NA
EMBO JOURNAL,MOLECULAR BIOLOGY & GENETICS,"The description of all reported data that includes statistical testing must state the name of the statistical test used to generate error bars and P values, the number (n) of independent experiments underlying each data point (not replicate measures of one sample), and the actual P value for each test (not merely 'significant' or 'P < 0.05'). Discussion of statistical methodology can be reported in the materials and methods section, but figure legends should contain a basic description of n, P and the test applied.","Since for complex biological experiments the number of independent repeats of a measurement often has to be limited for practical reasons, statistical measures with a very small n are commonplace. However, statistical measures applied to too small a sample size are not significant and they can suggest a false level of significance. We recommend that the actual individual data from each experiment should be plotted if n < 5, alongside an error bar. In cases where n is small, a justification for the use of the statistical test employed has to be provided.",NA,NA,NA,NA,NA
Journal of the Academy of Nutrition and Dietetics,AGRICULTURAL SCIENCES,"Use superscript letters to indicate footnotes (eg, a, b, c); however, use the standard * for P<0.05, ** for P<0.01, and *** for P<0.001. The asterisks indicating P values are only needed if the P values are not provided in the table. @@@ Use superscript letters to indicate footnotes (eg, a, b, c); however, use the standard * for P<0.05, ** for P<0.01, and *** for P<0.001. The asterisks indicating P values are only needed if the P values are not provided in the figure. @@@ Abstracts should be written in complete sentences and for a general journal readership, include P values, if appropriate, and be understandable without reference to the main text.","Only basic numbers should be included, but the author should indicate whether results were statistically significant or insignificant.",NA,NA,NA,NA,NA
PLOS BIOLOGY,BIOLOGY & BIOCHEMISTRY,NA,NA,NA,NA,NA,NA,NA
NUCLEIC ACIDS RESEARCH,BIOLOGY & BIOCHEMISTRY,"If p-values are presented, one-sided or two-sided should be specified. If one-sided, justification should be provided. Confidence intervals should also accompany the parameter for which statistical significance is being tested.","If p-values are presented, one-sided or two-sided should be specified. If one-sided, justification should be provided. Confidence intervals should also accompany the parameter for which statistical significance is being tested.",NA,NA,NA,NA,NA
Cancer Discovery,CLINICAL MEDICINE,NA,NA,NA,NA,NA,NA,NA
BMJ-British Medical Journal,CLINICAL MEDICINE,"Provide specifics about the evidence you discuss. For
example, for key statements, please say: “A large, well
conducted, randomised controlled trial showed INSERT
number [CI] and or p value” ... P values should always be accompanied by supporting data","main results with    (for    quantitative    studies)      95%      confidence      intervals      and,      where      appropriate,   the   exact   level   of   statistical   significance... Please do not use the term ‘negative’ to describe studies that have not found statistically significant differences, perhaps because  they  were  too  small.  There  will  always  be  some  uncertainty, and we hope you will be as explicit as possible in  reporting  what  you  have  found  in  your  study.  Using  wording such as “our results are compatible with a decrease of  this  much  or  an  increase  of  this  much”  or  ‘this  study  found  no  effect’  is  more  accurate  and  helpful  to  readers  than  “there  was  no  effect/no  difference.”",NA,NA,NA,NA,NA
JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION,CLINICAL MEDICINE,"Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). P values should never be presented alone without the data that are being compared. If P values are reported, follow standard conventions for decimal places: for P values less than .001, report as ""P<.001""; for P values between .001 and .01, report the value to the nearest thousandth; for P values greater than or equal to .01, report the value to the nearest hundredth; and for P values greater than .99, report as ""P>.99."" For studies with exponentially small P values (eg, genetic association studies), P values may be reported with exponents (eg, P = 1×10−5). In general, there is no need to present the values of test statistics (eg, F statistics or χ² results) and degrees of freedom when reporting results.","Define statistical terms, abbreviations, and symbols, if included. Avoid nontechnical uses of technical terms in statistics, such as correlation, normal, predictor, random, sample, significant, trend. Do not use inappropriate hedge terms such as marginal significance or trend toward significance for results that are not statistically significant...State any a priori levels of significance and whether hypothesis tests were 1- or 2-sided...Report basic numbers only but state if results are statistically significant or not significant;",NA,NA,NA,NA,NA
LANCET ONCOLOGY,CLINICAL MEDICINE,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
LANCET INFECTIOUS DISEASES,IMMUNOLOGY,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
EMERGING INFECTIOUS DISEASES,IMMUNOLOGY,"It is insufficient to only report p values as evidence of statistical significance. Authors must also report some measure of dispersion (e.g., standard deviations, confidence intervals).","It is insufficient to only report p values as evidence of statistical significance. Authors must also report some measure of dispersion (e.g., standard deviations, confidence intervals)...For statistical models, a table of results should provide the results of all the variables used in the model, the statistical significance of each variable, and a measure of goodness-of-fit of the entire model.",NA,NA,NA,NA,NA
Lancet HIV,IMMUNOLOGY,"p values should be given to two significant figures, unless p<0.0001",NA,NA,NA,NA,NA,NA
PLoS One,Multidisciplinary,"P-values. Report exact p-values for all values greater than or equal to 0.001. P-values less than 0.001 may be expressed as p < 0.001, or as exponentials in studies of genetic associations...Regression analyses. Include the full results of any regression analysis performed as a supplementary file. Include all estimated regression coefficients, their standard error, p-values, and confidence intervals, as well as the measures of goodness of fit.",Define the threshold for significance (alpha),NA,NA,NA,NA,NA
Science Advances,Multidisciplinary,"Results of each statistical test should be reported in full with the value of the test statistic and P value, and not simply reported as significant or nonsignificant; more than two significant digits on Pvalues are usually not needed except in situations of extreme multiple testing, such as in genetic association studies where stringent corrections for multiple testing might be used.","Results of each statistical test should be reported in full with the value of the test statistic and P value, and not simply reported as significant or nonsignificant
...
The testing level (alpha) and whether one-sided or two-sided testing was used should be reported for each statistical test; typically two-sided testing is appropriate, but if one-sided testing is used, its use should be justified.",NA,NA,NA,NA,NA
Scientific Reports,Multidisciplinary,"Every article that contains statistical testing should state...the actual P value for each test (not merely ""significant"" or ""P < 0.05"")...It should be clear what statistical test was used to generate every P value. Use of the word ""significant"" should always be accompanied by a P value; otherwise, use ""substantial,"" ""considerable,"" etc.","Every article that contains statistical testing should state...the alpha level for all tests...the actual P value for each test (not merely ""significant"" or ""P < 0.05"")... It should be clear what statistical test was used to generate every P value. Use of the word ""significant"" should always be accompanied by a P value; otherwise, use ""substantial,"" ""considerable,"" etc.",NA,NA,NA,NA,NA
JAMA Neurology,NEUROSCIENCE & BEHAVIOR,"Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). P values should never be presented alone without the data that are being compared.
...
For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). P values should never be presented alone without the data that are being compared. If P values are reported, follow standard conventions for decimal places: for P values less than .001, report as ""P<.001""; for P values between .001 and .01, report the value to the nearest thousandth; for P values greater than or equal to .01, report the value to the nearest hundredth; and for P values greater than .99, report as ""P>.99."" For studies with exponentially small P values (eg, genetic association studies), P values may be reported with exponents (eg, P = 1×10−5).","Do not use inappropriate hedge terms such as marginal significance or trend toward significance for results that are not statistically significant. 
...
Report basic numbers only but state if results are statistically significant or not significant
...
State any a priori levels of significance and whether hypothesis tests were 1- or 2-sided",NA,NA,NA,NA,NA
BRITISH JOURNAL OF PHARMACOLOGY,PHARMACOLOGY & TOXICOLOGY,"BJP has rules on minimum group sizes (stated above), but determination of the precise group size sufficient to permit statistical analysis is normally undertaken using approaches such as power analysis that take into account the anticipated ‘spread’ of the data. These approaches identify the minimum group size that will allow detection of a difference at a predefined P value, and therefore if this minimum value is selected there is a high risk of ‘false negative’ findings. @@@ Clearly, group size should be determined a priori such that an expected effect on the variable of primary interest can easily be detected using the predefined P threshold (we refer readers to our advice on determining group sizes). However, such group sizes may be insufficient for reliable detection of effects on secondary and subsidiary variables. It is the responsibility of the author to explain this in the paper, especially if they wish to argue that an apparent lack of effect was due to a type 2 error (false negative). We additionally encourage authors to be aware that the calculated P value is almost always bigger than it seems (‘less significant’) owing to the false discovery rate which is one reason why some investigators argue that most (rather than just some) research findings are false (Colquhoun 2014; Begley 2013; Begley & Ioannidis 2015). @@@ authors must define what level of P they consider to constitute statistical significance within the Methods section of the paper. Authors may choose a more stringent P threshold than the current norm of P < 0.05, but this must not be changed from one part of a manuscript to another. @@@ The threshold P value deemed to constitute statistical significance should be defined in the Methods and this value only should be used to denote statistical significance in the Results.","When comparing groups, and if a level of probability (p) is deemed to constitute the threshold for statistical significance, define this here in the ‘Data and Statistical Analysis’ sub-section of the Methods, and do not vary it later in Results (by presentation of multiple levels of significance). Thus, if p<0.05 is defined by the authors as threshold, p<0.01 etc. should not appear in the results. However, setting p at a lower value such as p<0.01 or 0.001 is acceptable (and considered good practice), provided that this is defined as constituting statistical significance, and is not varied. It is not necessary to state the exact level of p. @@@@ Statistical significance
The majority of papers published in BJP contain data sets
where several test groups are compared with a control
group in order to examine whether a drug has ‘an effect’.
In this context, statistics are used to inform a binary decision
about whether there is an effect or not. BJP continues
with the policy that authors must define what level of P
they consider to constitute statistical significance within
the Methods section of the paper. Authors may choose a
more stringent P threshold than the current norm of
P < 0.05, but this must not be changed from one part of a
manuscript to another.
Statistical analysis does not guarantee that a finding is
necessarily correct, and we will allow an author the right
to argue that a false positive or a false negative finding
may have been generated. This issue is particularly relevant
to variables of secondary interest. Clearly, group size should
be determined a priori such that an expected effect on the
variable of primary interest can easily be detected using
the predefined P threshold (we refer readers to our advice
on determining group sizes). However, such group sizes
may be insufficient for reliable detection of effects on secondary
and subsidiary variables. It is the responsibility of
the author to explain this in the paper, especially if they
wish to argue that an apparent lack of effect was due to a
type 2 error (false negative). We additionally encourage authors
to be aware that the calculated P value is almost always
bigger than it seems (‘less significant’) owing to the
false discovery rate which is one reason why some investigators
argue that most (rather than just some) research findings
are false (Colquhoun 2014; Begley 2013; Begley &
Ioannidis 2015).",NA,NA,NA,NA,NA
PLANT BIOTECHNOLOGY JOURNAL,PLANT & ANIMAL SCIENCE,"All abbreviations must be defined in footnotes. Footnote symbols: †, ‡, §, ¶, should be used (in that order) and *, **, *** should be reserved for P-values.",NA,NA,NA,NA,NA,NA
PSYCHOLOGICAL SCIENCE,PSYCHIATRY_PSYCHOLOGY,"exact p values should be reported for all results greater than .001; p values below this range should be described as “p < .001.” 
","Psychological Science recommends the use of the “new statistics”—effect sizes, confidence intervals, and meta-analysis—to avoid problems associated with null-hypothesis significance testing (NHST).",NA,NA,NA,NA,NA
JAMA Psychiatry,PSYCHIATRY_PSYCHOLOGY,"When possible, present numerical results (eg, absolute numbers and/or rates) with appropriate indicators of uncertainty, such as confidence intervals. Use means and standard deviations (SDs) for normally distributed data and medians and ranges or interquartile ranges (IQRs) for data that are not normally distributed. Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI −0.2% to 1.8%; P = .13). P values should never be presented alone without the data that are being compared. If P values are reported, follow standard conventions for decimal places: for P values less than .001, report as ""P<.001""; for P values between .001 and .01, report the value to the nearest thousandth; for P values greater than or equal to .01, report the value to the nearest hundredth; and for P values greater than .99, report as ""P>.99."" For studies with exponentially small P values (eg, genetic association studies), P values may be reported with exponents (eg, P = 1×10−5). In general, there is no need to present the values of test statistics (eg, F statistics or χ² results) and degrees of freedom when reporting results.
@@@
For randomized trials using parallel-group design, there is no validity in conducting hypothesis tests regarding the distribution of baseline covariates between groups; by definition, these differences are due to chance. Because of this, tables of baseline participant characteristics should not include P values or statements of statistical comparisons among randomized groups. Instead, report clinically meaningful imbalances between groups, along with potential adjustments for those imbalances in multivariable models. To read more about statistical tests and data presentation, see the AMA Manual of Style
@@@
Avoid solely reporting the results of statistical hypothesis testing, such as P values, which fail to convey important quantitative information. For most studies, P values should follow the reporting of comparisons of absolute numbers or rates and measures of uncertainty (eg, 0.8%, 95% CI -0.2% to 1.8%; P = .13). P values should never be presented alone without the data that are being compared. See also Reporting Standards and Data Presentation.
@@@
In the reporting of results, when possible, quantify findings and present them with appropriate indicators of measurement error or uncertainty, such as confidence intervals (see Reporting Standards and Data Presentation). Avoid relying solely on statistical hypothesis testing, such as the use of P values, which fails to convey important quantitative information. 

","Report basic numbers only but state if results are statistically significant or not significant; do not include results of statistical tests or measures of variance (see example below). 
@@@
Avoid nontechnical uses of technical terms in statistics, such as correlation, normal, predictor, random, sample, significant, trend. Do not use inappropriate hedge terms such as marginal significance or trend toward significance for results that are not statistically significant.
@@@
State any a priori levels of significance and whether hypothesis tests were 1- or 2-sided.
@@@
",NA,NA,NA,NA,NA
Lancet Psychiatry,PSYCHIATRY_PSYCHOLOGY,"p values should be given to two significant figures, unless p<0·0001",NA,NA,NA,NA,NA,NA
Conservation Letters,ENVIRONMENT_ECOLOGY,"Any article reporting p-values must also report 95% Confidence Intervals (CIs) in the text and in figures. All figures that include data used in statistical analyses must show error bars on the figure, either in the main text or Supporting Information. Where possible, these error bars should show 95% CIs, but in all cases authors must be explicit about what the error bars show.",NA,NA,NA,NA,NA,NA
AMERICAN SOCIOLOGICAL REVIEW,"SOCIAL SCIENCES, GENERAL","Generally, results at p > .05 (such as p < .10) should not be indicated as significant. Use asterisks *, **, and *** to indicate significance at the p < .05, p < .01, and p < .001 levels, respectively","Generally, results at p > .05 (such as p < .10) should not be indicated as significant.",NA,NA,NA,NA,NA
MOLECULAR ECOLOGY,ENVIRONMENT_ECOLOGY,"Tables - symbols  *, **, *** should be reserved for P-values",NA,NA,NA,NA,NA,NA
ALLERGY,IMMUNOLOGY,"Tables - symbols  *, **, *** should be reserved for P-values",NA,NA,NA,NA,NA,NA
AMERICAN JOURNAL OF POLITICAL SCIENCE,"SOCIAL SCIENCES, GENERAL",NA,Authors who report that results are “statistically significant” should use the 0.05 level or lower. Statistical tests using the 0.10 level are not acceptable for work submitted to the AJPS.,NA,NA,NA,NA,NA
Nature Plants,PLANT & ANIMAL SCIENCE,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Light-Science & Applications,PHYSICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Physics,PHYSICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
MOLECULAR PSYCHIATRY,NEUROSCIENCE & BEHAVIOR,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Methods,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
CELL RESEARCH,MOLECULAR BIOLOGY & GENETICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Medicine,MOLECULAR BIOLOGY & GENETICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Cell Biology,MOLECULAR BIOLOGY & GENETICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
npj Computational Materials,MATERIALS SCIENCE,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Mucosal Immunology,IMMUNOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Energy,ENGINEERING,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Communications,Multidisciplinary,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Biotechnology,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Geoscience,GEOSCIENCES,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Climate Change,ENVIRONMENT_ECOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Chemical Biology,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Protocols,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Chemistry,CHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Structural & Molecular Biology,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Cellular & Molecular Immunology,IMMUNOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Bone Research,BIOLOGY & BIOCHEMISTRY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Immunology,IMMUNOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Nanotechnology,MATERIALS SCIENCE,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Materials,MATERIALS SCIENCE,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Microbiology,MICROBIOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Genetics,MOLECULAR BIOLOGY & GENETICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature,Multidisciplinary,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Neuroscience,NEUROSCIENCE & BEHAVIOR,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Nature Photonics,PHYSICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
npj Quantum Information,PHYSICS,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
npj Biofilms and Microbiomes,MICROBIOLOGY,The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted [LSR],NA,NA,NA,NA,NA,NA
Cell Metabolism,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
Cell Host & Microbe,MICROBIOLOGY,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
IMMUNITY,IMMUNOLOGY,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
DEVELOPMENTAL CELL,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
CELL,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
MOLECULAR CELL,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
CURRENT BIOLOGY,BIOLOGY & BIOCHEMISTRY,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
Chem,CHEMISTRY,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
CANCER CELL,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
Cell Stem Cell,MOLECULAR BIOLOGY & GENETICS,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
NEURON,NEUROSCIENCE & BEHAVIOR,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
Cell Systems,BIOLOGY & BIOCHEMISTRY,NA,please summarize in this section how significance was defined,NA,NA,NA,NA,NA
Frontiers in Microbiology,MICROBIOLOGY,NA,NA,NA,NA,NA,NA,NA
FRONTIERS IN ECOLOGY AND THE ENVIRONMENT,ENVIRONMENT_ECOLOGY,NA,NA,NA,NA,NA,NA,NA
Scientific Data,Multidisciplinary,"Inherited Nature [LSR] guidance: The test results (e.g. P values) given as exact values whenever possible and with confidence intervals noted. Journal specific guidance: Data Descriptors should not test new hypotheses or provide extensive interpretive analysis, and therefore should not usually contain statistical significance testing. When hypothesis-based tests must be employed, authors should state the name of the statistical test; the n value for each statistical analysis; the comparisons of interest; a justification for the use of that test (including, for example, a discussion of the normality of the data when the test is appropriate only for normal data); the alpha level for all tests, whether the tests were one-tailed or two-tailed; and the actual p-value for each test (not merely ‘significant’ or ‘p < 0.05’). It should be clear what statistical test was used to generate every p-value...
Use of the word ‘significant’ should always be accompanied by a p-value; otherwise, use ‘substantial’, ‘considerable’, etc.","Journal specific guidance: Data Descriptors should not test new hypotheses or provide extensive interpretive analysis, and therefore should not usually contain statistical significance testing. When hypothesis-based tests must be employed, authors should state the name of the statistical test; the n value for each statistical analysis; the comparisons of interest; a justification for the use of that test (including, for example, a discussion of the normality of the data when the test is appropriate only for normal data); the alpha level for all tests, whether the tests were one-tailed or two-tailed; and the actual p-value for each test (not merely ‘significant’ or ‘p < 0.05’). It should be clear what statistical test was used to generate every p-value...
Use of the word ‘significant’ should always be accompanied by a p-value; otherwise, use ‘substantial’, ‘considerable’, etc.",NA,NA,NA,NA,NA
